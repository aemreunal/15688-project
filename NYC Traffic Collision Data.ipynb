{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Analyzing NYC Traffic Collision Data</center>\n",
    "## <center>A 15-688 Project by:</center><center><br/> Ahmet Emre Unal (ahmetemu)<br/><br/>Marco Peyrot (mpeyrotc)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New York City is a beautiful city with terrible traffic. The drivers are impatient and aggressive, which results in many traffic collisions every day, some of which, quite unfortunately, lead to injuries and death.\n",
    "\n",
    "For our project, we wanted to understand NYC's most collision-prone areas and try to predict collisions based on many factors, such as location, vehicle type, whether it's a weekday, etc.\n",
    "\n",
    "The [NYPD Motor Vehicle Collisions](https://data.cityofnewyork.us/Public-Safety/NYPD-Motor-Vehicle-Collisions/h9gi-nx95/data) dataset we found was surprisingly feature-rich and populous. It also meant that there were lots of collision instances with missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests \n",
    "import scipy\n",
    "from scipy.cluster.vq import kmeans, kmeans2, vq\n",
    "from scipy.spatial.distance import cdist\n",
    "from IPython.core.display import display, HTML\n",
    "from colour import Color\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Plotting\n",
    "import matplotlib\n",
    "matplotlib.use('svg')\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# For scikit-learn to chill out about deprecation\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "raw_data_file_name = 'NYPD_Motor_Vehicle_Collisions.csv'\n",
    "bicycle_lanes_page_url = 'http://www.nyc.gov/html/dot/html/bicyclists/lane-list.shtml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We started by cleaning up rows with empty and '`UNKNOWN`' values, throwing away about a third of the original dataset. We then dropped columns that either were unnecessary (like the reason for the crash, since this sort of information is not possible to infer before the collision, like the driver being distracted) or were too detailed (like the vehicle subtypes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def load_data(file_name):\n",
    "    collision = pd.read_csv(file_name, \n",
    "                            na_filter=False, \n",
    "                            parse_dates={'DATE_COMBINED' : ['DATE', 'TIME']}, \n",
    "                            infer_datetime_format=True)\n",
    "    \n",
    "    # Remove rows that don't have the necessary data\n",
    "    columns_to_check_for_empty = ['LOCATION', 'LATITUDE', 'LONGITUDE', 'BOROUGH',\n",
    "                                  'ZIP CODE', 'ON STREET NAME', 'CROSS STREET NAME', \n",
    "                                  'VEHICLE TYPE CODE 1', 'VEHICLE TYPE CODE 1']\n",
    "    for column in columns_to_check_for_empty:\n",
    "        collision = collision[collision[column] != '']\n",
    "        collision = collision[collision[column] != 'UNKNOWN']\n",
    "\n",
    "    # Drop unneeded columns\n",
    "    columns_to_drop = ['CONTRIBUTING FACTOR VEHICLE 1', 'CONTRIBUTING FACTOR VEHICLE 2', \n",
    "                       'CONTRIBUTING FACTOR VEHICLE 3', 'CONTRIBUTING FACTOR VEHICLE 4', \n",
    "                       'CONTRIBUTING FACTOR VEHICLE 5', 'LOCATION', 'OFF STREET NAME', \n",
    "                       'VEHICLE TYPE CODE 2', 'VEHICLE TYPE CODE 3', 'VEHICLE TYPE CODE 4', \n",
    "                       'VEHICLE TYPE CODE 5']\n",
    "    for column in columns_to_drop:\n",
    "        collision = collision.drop(column, axis=1)\n",
    "        \n",
    "    # Set column types\n",
    "    collision['ZIP CODE'] = collision['ZIP CODE'].astype(int)\n",
    "    collision['LATITUDE'] = collision['LATITUDE'].astype(float)\n",
    "    collision['LONGITUDE'] = collision['LONGITUDE'].astype(float)\n",
    "    \n",
    "    # Rename date column to just 'DATE'\n",
    "    collision = collision.rename(columns={'DATE_COMBINED':'DATE'})\n",
    "    \n",
    "    # Eliminate duplicates\n",
    "    collision = collision.drop_duplicates()\n",
    "    \n",
    "    # Reset index\n",
    "    collision = collision.reset_index(drop=True)\n",
    "    \n",
    "    return collision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We proceeded to create two temporal features:\n",
    "\n",
    " 1. Whether it occurred on a weekday or weekend\n",
    " 2. In what 'time period' in the day it occurred\n",
    "\n",
    "The 'time period' requires some explanation: We all know that morning and evening rush hours can be especially more collision-prone than daytime (around noon) and night time (after the evening rush and before the morning rush). We decided to create these four bins with the following time ranges:\n",
    "\n",
    " 1. Night Time: 00:00-06:59 & 20:00-00:00\n",
    " 2. Morning Rush: 07:00-10:59\n",
    " 3. Night Time: 00:00-06:59 & 20:00-00:00\n",
    " 4. Evening Rush: 16:00-19:59\n",
    "\n",
    "Together with the weekday/weekend feature, this allowed us to represent the date in a way that is meaningful to a machine learning algorithm. We also assumed that, as long as it's a weekday, the exact day (whether it's a Monday or a Thursday) is not significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_temporal_features(collision):\n",
    "    collision = _create_time_features(collision)\n",
    "    collision = _create_date_features(collision)\n",
    "    \n",
    "    # We're done with date, we can drop it\n",
    "    collision = collision.drop('DATE', axis=1)\n",
    "    \n",
    "    return collision\n",
    "    \n",
    "\n",
    "def _create_time_features(collision):\n",
    "    # Create one-hot time of day representation\n",
    "    ## Date part is unimportant\n",
    "    morning_rush_begin = pd.datetime(2000, 01, 01, 07, 00, 00).time()\n",
    "    morning_rush_end = pd.datetime(2000, 01, 01, 11, 00, 00).time()\n",
    "    evening_rush_begin = pd.datetime(2000, 01, 01, 16, 00, 00).time()\n",
    "    evening_rush_end = pd.datetime(2000, 01, 01, 20, 00, 00).time()\n",
    "    collision_time = collision['DATE'].dt.time\n",
    "    \n",
    "    ## Night Time 00:00-06:59 & 20:00-00:00\n",
    "    night_time = (collision_time >= evening_rush_end) | (collision_time < morning_rush_begin)\n",
    "    night_time_onehot = pd.get_dummies(night_time).loc[:, True].astype(int)\n",
    "    collision = collision.assign(NIGHT_TIME = night_time_onehot.values)\n",
    "    \n",
    "    ## Morning Rush 07:00-10:59\n",
    "    morning_rush = (collision_time >= morning_rush_begin) & (collision_time < morning_rush_end)\n",
    "    morning_rush_onehot = pd.get_dummies(morning_rush).loc[:, True].astype(int)\n",
    "    collision = collision.assign(MORNING_RUSH = morning_rush_onehot.values)\n",
    "    \n",
    "    ## Night time 00:00-06:59 & 20:00-00:00\n",
    "    day_time = (collision_time >= morning_rush_end) & (collision_time < evening_rush_begin)\n",
    "    day_time_onehot = pd.get_dummies(day_time).loc[:, True].astype(int)\n",
    "    collision = collision.assign(DAY_TIME = day_time_onehot.values)\n",
    "    \n",
    "    ## Evening Rush 16:00-19:59\n",
    "    evening_rush = (collision_time >= evening_rush_begin) & (collision_time < evening_rush_end)\n",
    "    evening_rush_onehot = pd.get_dummies(evening_rush).loc[:, True].astype(int)\n",
    "    collision = collision.assign(EVENING_RUSH = evening_rush_onehot.values)\n",
    "    \n",
    "    return collision\n",
    "\n",
    "def _create_date_features(collision):\n",
    "    # Create one-hot weekday/weekend representation\n",
    "    collision_day = collision['DATE'].dt.dayofweek\n",
    "    \n",
    "    ## Weekday 0, 1, 2, 3, 4\n",
    "    ## Weekend 5, 6\n",
    "    is_weekday = (collision_day <= 4)\n",
    "    is_weekday_onehot = pd.get_dummies(is_weekday).astype(int)\n",
    "    \n",
    "    ## Weekday\n",
    "    weekday_onehot = is_weekday_onehot.loc[:, True]\n",
    "    collision = collision.assign(WEEKDAY = weekday_onehot.values)\n",
    "\n",
    "    ## Weekend\n",
    "    weekend_onehot = is_weekday_onehot.loc[:, False]\n",
    "    collision = collision.assign(WEEKEND = weekend_onehot.values)\n",
    "    \n",
    "    return collision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We further proceeded to create a one-hot encoding of the vehicle types that were available in the dataset. NYPD has put almost half of the vehicles in a general group called '`PASSENGER VEHICLE`', which seems to represent the common sedan type of vehicle. Other types, like SUVs, motorcycles, small and large commercial vehicles, have their own types. \n",
    "\n",
    "We removed some collision types (like the collisions in which the vehicle was an '`AMBULANCE`') with very few collisions. This further cut about 5% of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_vehicle_features(collision):\n",
    "    # Create one-hot vehicle type representation\n",
    "    vehicle_types_onehot = pd.get_dummies(collision.loc[:, 'VEHICLE TYPE CODE 1']).astype(int)\n",
    "    \n",
    "    # Merge Motorcycle & Scooter columns\n",
    "    motorcycle = vehicle_types_onehot.loc[:, 'MOTORCYCLE'] + vehicle_types_onehot.loc[:, 'SCOOTER']\n",
    "    vehicle_types_onehot = vehicle_types_onehot.drop('MOTORCYCLE', axis=1)\n",
    "    vehicle_types_onehot = vehicle_types_onehot.drop('SCOOTER', axis=1)\n",
    "    vehicle_types_onehot = vehicle_types_onehot.assign(MOTORCYCLE = motorcycle.values)\n",
    "    \n",
    "    # Concatanate one-hot with collisions\n",
    "    collision = pd.concat([collision, vehicle_types_onehot], axis=1)\n",
    "    \n",
    "    # Drop unneeded collisions\n",
    "    vehicles_to_drop = ['OTHER', 'AMBULANCE', 'PEDICAB', 'FIRE TRUCK', 'LIVERY VEHICLE']\n",
    "    collisions_to_drop = vehicle_types_onehot.loc[:, vehicles_to_drop[0]]\n",
    "    for i in xrange(1, len(vehicles_to_drop)):  # Start from 1 since we already have OTHER\n",
    "        collisions_to_drop += vehicle_types_onehot.loc[:, vehicles_to_drop[i]]\n",
    "    collisions_to_keep = (collisions_to_drop == 0)\n",
    "    collision = collision[collisions_to_keep]\n",
    "    collision = collision.reset_index(drop=True)  # Reset index due to dropped rows\n",
    "    \n",
    "    # Drop unneeded vehicle columns\n",
    "    for column in vehicles_to_drop:\n",
    "        collision = collision.drop(column, axis=1)\n",
    "    \n",
    "    # Drop vehicle type column\n",
    "    collision = collision.drop('VEHICLE TYPE CODE 1', axis=1)\n",
    "        \n",
    "    return collision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We proceeded by assigning a 'severity score' to each collision. Each collision, by default, has a severity score of 1. The score increases by 2 for each injury and by 10 for each death. These are arbitrary values we came up with and have no bearing on the cost of life in these collisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Default score values\n",
    "INJURY_SCORE = 2\n",
    "DEATH_SCORE = 10\n",
    "\n",
    "def create_severity_score_feature(collision):\n",
    "    # Give all collisions a score of 1 by default\n",
    "    collision['SEVERITY SCORE'] = 1\n",
    "    \n",
    "    # For each injury, add to the score of the collision\n",
    "    collision['SEVERITY SCORE'] += (collision.loc[:, 'NUMBER OF PERSONS INJURED'] * INJURY_SCORE)\n",
    "    \n",
    "    # For each death, add to the score of the collision\n",
    "    collision['SEVERITY SCORE'] += (collision.loc[:, 'NUMBER OF PERSONS KILLED'] * DEATH_SCORE)\n",
    "    \n",
    "    return collision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load the collision data\n",
    "collision = load_data(raw_data_file_name)\n",
    "collision = create_temporal_features(collision)\n",
    "collision = create_vehicle_features(collision)\n",
    "collision = create_severity_score_feature(collision)\n",
    "\n",
    "print collision.head()\n",
    "print collision.dtypes\n",
    "print len(collision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We proceed with parsing NYC's [bike lanes list web page](http://www.nyc.gov/html/dot/html/bicyclists/lane-list.shtml) to add another feature to our collision data: whether the street the collision occurred in had a bicycle lane or not. We do that by manually parsing the bicycle lanes page and matching them to the street names of collisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_bicycle_lanes_from_page(page_html):\n",
    "    \"\"\"\n",
    "    Parse the table contained in the bicycle lanes webpage.\n",
    "\n",
    "    Args:\n",
    "        page_html (string): String of HTML corresponding to the data source webpage.\n",
    "\n",
    "    Returns:\n",
    "        a dictionary that contains mappings from a category to the list containing the data.\n",
    "        These categories are: street, begins, ends, and borough.\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(page_html, 'html.parser')\n",
    "    bicycle_lanes_list = {\n",
    "        'street': [],\n",
    "        'begins': [],\n",
    "        'ends': [],\n",
    "        'borough': []\n",
    "    }\n",
    "\n",
    "    table = soup.findChildren('tbody')[0]\n",
    "    rows = table.findChildren(['tr'])\n",
    "    \n",
    "    for row in rows:\n",
    "        cells = row.findChildren('td')\n",
    "        content = cells[0].text\n",
    "        m = re.search(r'^([a-zA-Z\\s0-9\\-\\.,\\(\\)]+) (from)*(between)* '\n",
    "                      r'([a-zA-Z\\s0-9\\-\\.,\\(\\)]+) (to)*(and)* '\n",
    "                      r'([a-zA-Z\\s0-9\\-\\.,\\(\\)]+)$', content)\n",
    "        \n",
    "        # Content that does not follow this syntax is discarded because\n",
    "        # it refers to landscapes or parks.\n",
    "        if m is not None:\n",
    "            bicycle_lanes_list['street'].append(m.group(1).upper())\n",
    "            bicycle_lanes_list['begins'].append(m.group(4).upper())\n",
    "            bicycle_lanes_list['ends'].append(m.group(7).upper())\n",
    "            bicycle_lanes_list['borough'].append(cells[2].text.upper())\n",
    "\n",
    "    return bicycle_lanes_list\n",
    "    \n",
    "def extract_bicycle_lanes(url):\n",
    "    \"\"\"\n",
    "    Retrieve all of the bicycle lane information for the city of New York.\n",
    "\n",
    "    Parameters:\n",
    "        url (string): page URL corresponding to the listing of bicycle lane information.\n",
    "\n",
    "    Returns:\n",
    "        bicycle_lanes (Pandas DataFrame): list of dictionaries containing extracted lane information.\n",
    "    \"\"\"\n",
    "    bicycle_lanes_page = requests.get(url).text\n",
    "    bicycle_lanes_list = get_bicycle_lanes_from_page(bicycle_lanes_page)\n",
    "            \n",
    "    bicycle_lanes = pd.DataFrame(bicycle_lanes_list)\n",
    "    bicycle_lanes.loc[bicycle_lanes.borough == 'THE BRONX', 'borough'] = 'BRONX'\n",
    "    columns_to_rename = {'borough': 'BOROUGH', 'begins': 'BEGINS', 'ends': 'ENDS', 'street': 'ON STREET NAME'}\n",
    "    bicycle_lanes = bicycle_lanes.rename(columns=columns_to_rename)\n",
    "    \n",
    "    return bicycle_lanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bicycle_lanes = extract_bicycle_lanes(bicycle_lanes_page_url)\n",
    "\n",
    "print bicycle_lanes.head()\n",
    "print len(bicycle_lanes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bicycle lanes are defined by four features:\n",
    "\n",
    " 1. Which street they're on (`ON STREET NAME`)\n",
    " 2. Which cross street they begin on (`BEGINS`)\n",
    " 3. Which cross street they end on (`ENDS`)\n",
    " 4. The borough they're on (`BOROUGH`)\n",
    " \n",
    "By using these four values, we'll match them to the location of the collisions and add a 'HAS_BIKE_LANE' column to the collisions data frame, indicating whether the crash occurred on a street that has a bike lane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def merge_bicycle_lanes(df1, df2, columns):\n",
    "    # Populate collisions with bicycle lane data by matching on 'columns'\n",
    "    result = pd.merge(df1, df2, how='left', on=columns)\n",
    "    \n",
    "    # Create a 'HAS_BIKE_LANE' column to indicate the presenc of a bike lane\n",
    "    result = result.assign(HAS_BIKE_LANE = [0 if x is np.nan else 1 for x in result.loc[:, 'BEGINS']])\n",
    "    \n",
    "    # Drop unneeded columns\n",
    "    result = result.drop('BEGINS', axis=1)\n",
    "    result = result.drop('ENDS', axis=1)\n",
    "    \n",
    "    # Multiple bike lanes can be on the same street, disregard that fact\n",
    "    result = result.drop_duplicates()\n",
    "    \n",
    "    # Reset index to account for duplicates\n",
    "    result = result.reset_index(drop=True)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "collision = merge_bicycle_lanes(collision, bicycle_lanes, ['ON STREET NAME', 'BOROUGH'])\n",
    "\n",
    "print collision.head()\n",
    "print collision.dtypes\n",
    "print len(collision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "We now need to find areas in which collisions occur frequently. This will let us identify collision-prone areas in NYC. All the collisions we have right now have their latitude & longitude information, which is too granular to identify areas. We also have the borough and Zip codes of the locations, but those are not granular enough. What we need to do is to define 'clusters' from the locations of crashes, which we can use to determine areas. We can use the k-means algorithm to achieve this.\n",
    "\n",
    "Usually, we try to optimize the number of means to give us a good balance of error & generalizability. While we can do that here as well, we can manually choose the number of means to specify how granular we'd like to be with our zoning: selecting a single mean will, naturally, cover the entire NYC metropolitan area but won't provide us with any additional information. By visually observing the results of choosing from a number of means, we can find a good balance of the number of zones that translate logically to the layout of the NYC metropolitan area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**NOTE:**\n",
    "Below is our test code for running the k-means algorithm on our dataset. For our final report, we will be identifying and obtaining the zones from our collision data using k-means, assigning zone IDs (the means) to the collisions and use this final version to perform predictions on future data (for example, given a car's features and the zone, predicting the expected number of injuries from a collision)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def k_means_test(X, K_max):\n",
    "    \"\"\"\n",
    "    Finds the best number k for the k_means algorithm according to some features passed to this\n",
    "    method.\n",
    "    \n",
    "    Some code has been taken from: \n",
    "    https://stackoverflow.com/questions/6645895/calculating-the-percentage-of-variance-measure-for-k-means\n",
    "    especially the plotting parts.\n",
    "\n",
    "    Parameters:\n",
    "        X (DataFrame): pandas dataframe containing the features that will be used to divide the\n",
    "        data into clusters.\n",
    "        K-max (Integer): the maximum number of K clusters to test on.\n",
    "\n",
    "    Returns:\n",
    "        Nothing, it just plots the elbow graph that has a marker on the best number of\n",
    "        clusters to use.\n",
    "    \"\"\"\n",
    "    K = range(1, K_max)\n",
    "    KM = [kmeans(X,k) for k in K]\n",
    "    centroids = [cent for (cent,var) in KM]\n",
    "\n",
    "    D_k = [cdist(X, cent, 'euclidean') for cent in centroids]\n",
    "    cIdx = [np.argmin(D,axis=1) for D in D_k]\n",
    "    dist = [np.min(D,axis=1) for D in D_k]\n",
    "    avgWithinSS = [sum(d)/X.shape[0] for d in dist]\n",
    "    \n",
    "    # Choose k\n",
    "    kIdx = min([(v,i) for i,v in enumerate([((x*100) + y)/2.0 for x,y in zip(avgWithinSS, K)])])[1]\n",
    "\n",
    "    # Plot elbow curve\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(K, avgWithinSS, 'b*-')\n",
    "    ax.plot(K[kIdx], avgWithinSS[kIdx], marker='o', markersize=12, \n",
    "            markeredgewidth=2, markeredgecolor='r', markerfacecolor='None')\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('Average within-cluster sum of squares')\n",
    "    plt.title('Elbow for K-Means clustering')\n",
    "\n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate different centroids according to different number of k's.\n",
    "k_means_test(collision.loc[:,['LATITUDE', 'LONGITUDE']], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "location_data = collision.loc[:, ['LATITUDE', 'LONGITUDE']]\n",
    "centroids, labels = kmeans2(location_data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createPage(title, script):\n",
    "    \"\"\"\n",
    "    Creates a webpage that will hold the map where the points of each cluster are plotted. This page\n",
    "    shows an instance of Leaflet (http://leafletjs.com/).\n",
    "\n",
    "    Parameters:\n",
    "        title (string): the name of the webpage that will appear on the browser\n",
    "        script (string): the location of the file that contains the plotting information (must be a\n",
    "                        javascript file)\n",
    "\n",
    "    Returns:\n",
    "        The HTML code that forms the webpage.\n",
    "    \"\"\"\n",
    "    \n",
    "    page = \"\"\"\n",
    "        <!DOCTYPE html>\n",
    "        <html>\n",
    "            <head>\n",
    "                <title>TITLE</title>\n",
    "                <meta charset=\"utf-8\" />\n",
    "                <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "\n",
    "                <link rel=\"stylesheet\" href=\"https://unpkg.com/leaflet@1.0.2/dist/leaflet.css\" />\n",
    "                <script src=\"https://unpkg.com/leaflet@1.0.2/dist/leaflet.js\"></script>\n",
    "            </head>\n",
    "            <body>\n",
    "                <div id=\"mapid\" style=\"width: 800px; height: 600px;\"></div>\n",
    "                <script src=\"SCRIPT\"></script>\n",
    "            </body>\n",
    "        </html>\n",
    "\n",
    "        \"\"\"\n",
    "    \n",
    "    page = page.replace(\"TITLE\", title)\n",
    "    page = page.replace(\"SCRIPT\", script)\n",
    "    \n",
    "    return page\n",
    "\n",
    "def createScript(name, lat, lon, zoom):\n",
    "    \"\"\"\n",
    "    Creates a javascript file with the basic content to display a map in a webpage.\n",
    "\n",
    "    Parameters:\n",
    "        name (string): the name (or directory) of the javascript file to be created\n",
    "        lat (float): the latitude where the map will be centered\n",
    "        lon (float): the longitude where the map will be centered\n",
    "        zoom (int): the zoom level in which the map starts (can be changed in browser)\n",
    "\n",
    "    Returns:\n",
    "        Nothing, the file is written onto disk\n",
    "    \"\"\"\n",
    "    \n",
    "    script = \"\"\"    \n",
    "    var mymap = L.map('mapid').setView([LAT, LON], ZOOM);\n",
    "    \n",
    "    L.tileLayer('https://api.tiles.mapbox.com/v4/{id}/{z}/{x}/{y}.png?access_token=pk.eyJ1IjoibWFwYm94IiwiYSI6ImNpandmbXliNDBjZWd2M2x6bDk3c2ZtOTkifQ._QA7i5Mpkd_m30IGElHziw', {\n",
    "        maxZoom: 18,\n",
    "        attribution: 'Map data &copy; <a href=\"http://openstreetmap.org\">OpenStreetMap</a> contributors, ' +\n",
    "            '<a href=\"http://creativecommons.org/licenses/by-sa/2.0/\">CC-BY-SA</a>, ' +\n",
    "            'Imagery Â© <a href=\"http://mapbox.com\">Mapbox</a>',\n",
    "        id: 'mapbox.streets'\n",
    "    }).addTo(mymap);\n",
    "    \n",
    "    \"\"\"\n",
    "    script = script.replace(\"LAT\", str(lat))\n",
    "    script = script.replace(\"LON\", str(lon))\n",
    "    script = script.replace(\"ZOOM\", str(zoom))\n",
    "    \n",
    "    with open(name + '.js', \"w\") as script_file:\n",
    "        script_file.write(script)\n",
    "        \n",
    "def appendScript(name, lats, lngs, color, size):\n",
    "    \"\"\"\n",
    "    Appends to a javascript file all the points to be plotted with a given color and size\n",
    "\n",
    "    Parameters:\n",
    "        name (string): the name (or directory) of the javascript file to be used\n",
    "        lats (list[float]): the list of latitudes to be plotted\n",
    "        lngs (list[float]): the list of longitudes to be plotted\n",
    "        color (Color): the color in which the points will be plotted\n",
    "        size (int): the size of each point\n",
    "\n",
    "    Returns:\n",
    "        Nothing, the file is written onto disk\n",
    "    \"\"\"\n",
    "    \n",
    "    point = \"\"\"\n",
    "    L.circle([LAT, LON], SIZE, {\n",
    "        color: 'COLOR',\n",
    "        fillColor: 'COLOR',\n",
    "        fillOpacity: 0.5\n",
    "    }).addTo(mymap);\n",
    "    \"\"\"\n",
    "    \n",
    "    point = point.replace('SIZE', str(size))\n",
    "    point = point.replace('COLOR', str(color.hex))\n",
    "        \n",
    "    with open(name + '.js', \"a\") as script_file:\n",
    "        for lat, lon in zip(lats, lngs):\n",
    "            new_point = point.replace('LAT', str(lat))\n",
    "            new_point = new_point.replace('LON', str(lon)) \n",
    "            script_file.write(new_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plotFeature(X, features, script, html_file, lat=40.77, lon=-74.009725, zoom=12, \n",
    "                severity=False, simple=False, centroids = None, ids =None):\n",
    "    \"\"\"\n",
    "    Creates a html file and a javascript file that will hold a map of a region centered at the specified latitude\n",
    "    and logitude coordinates. It will plot several points based on the labels passed on to it and the number\n",
    "    of clusters they map to.\n",
    "    \n",
    "    Parameters:\n",
    "        X (pandas df): a dataframe that contains latitude and longitude values\n",
    "        labels (list): holds the label for which each row in X is assigned to a cluster\n",
    "        script (string): the name (or directory) of the javascript file to be used\n",
    "        html_file (string): the name (or directory) of the html file to be used\n",
    "        num_points (int): the maximum number of points to be plotted per cluster\n",
    "        lat (float): the latitude where the map will be centered\n",
    "        lon (float): the longitude where the map will be centered\n",
    "        zoom (int): the zoom level in which the map starts (can be changed in browser)\n",
    "        \n",
    "    Returns:\n",
    "        Nothing, the files are written onto disk\n",
    "    \"\"\"     \n",
    "    with open(html_file + '.html', \"w\") as map_file:\n",
    "        map_file.write(createPage(html_file, script + '.js'))\n",
    "        \n",
    "    createScript(script, lat, lon, zoom)\n",
    "    \n",
    "    assignments = X\n",
    "    \n",
    "    for feature in features:\n",
    "        assignments = assignments.loc[assignments[feature] == 1, :]\n",
    "\n",
    "    assignments = assignments.loc[:,['LATITUDE', 'LONGITUDE', 'SEVERITY SCORE']]\n",
    "    \n",
    "    separate = False\n",
    "    if centroids is not None:\n",
    "        separate = True\n",
    "        assignments['ids'] = ids\n",
    "    else:\n",
    "        centroids = [0,0]\n",
    "    \n",
    "    prim_colors = ['Red', 'Blue', 'Purple', 'Green']\n",
    "    \n",
    "    for center in xrange(len(centroids)):\n",
    "        if separate:\n",
    "            assignments2 = assignments.loc[assignments['ids'] == center, :]\n",
    "        else:\n",
    "            assignments2 = assignments\n",
    "        \n",
    "        if severity:\n",
    "            orange = Color(\"Yellow\")\n",
    "            colors = list(orange.range_to(prim_colors[center], len(set(assignments2.loc[:,'SEVERITY SCORE']))))\n",
    "            for index, label in enumerate(sorted(set(assignments2.loc[:,'SEVERITY SCORE']))):\n",
    "                x = assignments2.loc[assignments['SEVERITY SCORE'] == label, :]\n",
    "                appendScript(script, x.loc[:,'LATITUDE'], x.loc[:,'LONGITUDE'], colors[index], 50) \n",
    "        else:\n",
    "            x = assignments2\n",
    "            appendScript(script, x.loc[:,'LATITUDE'], x.loc[:,'LONGITUDE'], Color(prim_colors[center]), 50)\n",
    "            if simple:\n",
    "                appendScript(script, [centroids[center][0]], [centroids[center][1]], Color(\"Orange\"), 150)\n",
    "            \n",
    "        if centroids is None:\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "collision1 = collision.drop(['ON STREET NAME', 'CROSS STREET NAME', 'UNIQUE KEY'], axis=1)\n",
    "plotFeature(collision1, ['NIGHT_TIME', 'MOTORCYCLE'], 'file', 'page', severity=True, centers=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "One of the mosst useful functions for visualizing this kind of data is plotFeature. It takes any data frame and\n",
    "plots the collisions on an interative map of New York City. In essence we pass to it the number of clusters we want to\n",
    "divide the data into and if we want to also show the severity of the crashes as a heatmap. These last two options are\n",
    "optional. So, for example: we can visualize the severity of crashes in the borough of Queens by 3 clusters that\n",
    "ocurred during night time and only involved Taxi vehicles.\n",
    "\n",
    "## A simple example\n",
    "\n",
    "With this function, we started mixing features looking for some visual result that showed an interesting fact. During\n",
    "this process we decided to analyze further the accidents that occur on streets with bike lanes. We know that traffic\n",
    "changes in quantity between week and the weekend, so we decided to view accidents that are caused by Taxis in the\n",
    "Manhattan borough. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plotFeature(collision1.loc[collision1['BOROUGH'] == 'MANHATTAN',:], ['NIGHT_TIME', 'TAXI', 'WEEKDAY', 'HAS_BIKE_LANE'], 'file1', 'TAXI - WEEKDAY - BIKE 2', severity=True, centers=None, simple=False)\n",
    "plotFeature(collision1.loc[collision1['BOROUGH'] == 'MANHATTAN',:], ['NIGHT_TIME', 'TAXI', 'WEEKEND', 'HAS_BIKE_LANE'], 'file2', 'TAXI - WEEKEND - BIKE 2', severity=True, centers=None, simple=False)\n",
    "\n",
    "plotFeature(collision1.loc[collision1['BOROUGH'] == 'MANHATTAN',:], ['NIGHT_TIME', 'BUS', 'WEEKDAY', 'HAS_BIKE_LANE'], 'file3', 'BUS - WEEKDAY - BIKE 2', severity=True, centers=None, simple=False)\n",
    "plotFeature(collision1.loc[collision1['BOROUGH'] == 'MANHATTAN',:], ['NIGHT_TIME', 'BUS', 'WEEKEND', 'HAS_BIKE_LANE'], 'file4', 'BUS - WEEKEND - BIKE 2', severity=True, centers=None, simple=False)\n",
    "\n",
    "plotFeature(collision1.loc[collision1['BOROUGH'] == 'MANHATTAN',:], ['DAY_TIME', 'TAXI', 'WEEKDAY', 'HAS_BIKE_LANE'], 'file9', 'TAXI - WEEKDAY - BIKE 1', severity=True, centers=None, simple=False)\n",
    "plotFeature(collision1.loc[collision1['BOROUGH'] == 'MANHATTAN',:], ['DAY_TIME', 'TAXI', 'WEEKEND', 'HAS_BIKE_LANE'], 'file10', 'TAXI - WEEKEND - BIKE 1', severity=True, centers=None, simple=False)\n",
    "\n",
    "plotFeature(collision1.loc[collision1['BOROUGH'] == 'MANHATTAN',:], ['DAY_TIME', 'BUS', 'WEEKDAY', 'HAS_BIKE_LANE'], 'file11', 'BUS - WEEKDAY - BIKE 1', severity=True, centers=None, simple=False)\n",
    "plotFeature(collision1.loc[collision1['BOROUGH'] == 'MANHATTAN',:], ['DAY_TIME', 'BUS', 'WEEKEND', 'HAS_BIKE_LANE'], 'file12', 'BUS - WEEKEND - BIKE 1', severity=True, centers=None, simple=False)\n",
    "\n",
    "plotFeature(collision1.loc[collision1['BOROUGH'] == 'MANHATTAN',:], ['MORNING_RUSH', 'TAXI', 'WEEKDAY'], 'file5', 'TAXI - WEEKDAY - RUSH MOR', severity=True, centers=None, simple=False)\n",
    "plotFeature(collision1.loc[collision1['BOROUGH'] == 'MANHATTAN',:], ['EVENING_RUSH', 'TAXI', 'WEEKDAY'], 'file6', 'TAXI - WEEKDAY - RUSH EVE', severity=True, centers=None, simple=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "collision1 = collision1.loc[collision1['BOROUGH'] == 'MANHATTAN',:]\n",
    "\n",
    "plotFeature(collision1.loc[collision1['LATITUDE'] < 40.74,:], ['BUS'], 'file1', 'Bla', severity=False, simple=False)\n",
    "plotFeature(collision1.loc[collision1['LATITUDE'] < 40.74,:], ['BUS'], 'file2', 'blu', severity=False, simple=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Prediction\n",
    "\n",
    "We have spent time and effort in extracting a bunch of features for all the collisions. The question remains, however: how good are all these features in describing a collision's severity? In other words, how well can we predict the severity of a collision through the use of these features?\n",
    "\n",
    "Let's start by discribing the baseline: Most collisions in the data set do not have any injuries or deaths. If we simply return a severity of '1', we will correctly predict the severity of ~80% of collisions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score = sum(collision['SEVERITY SCORE'] == 1) / float(len(collision))\n",
    "accuracy = '{:.4f}%'.format(score * 100)\n",
    "print 'Baseline:', accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Let's try to see how well some individual features can predict the severity in order to compare it to the combined features' effectiveness. Let's try the time of day.\n",
    "\n",
    "It might seem reasonable to expect the most severe collisions to happen during rush hours. Therefore, the time of day might also seem like a good predictor of the severity of the collision. We can test this hypothesis by randomly choosing a subset of our collisions, running logistic regression on it by using just the 'time of day' feature and testing it on a verification set, also randomly chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_training_sets(collision):\n",
    "    \"\"\"Gets a list of collisions and returns the set of training features and \n",
    "    labels from them. The severity score of each collision are their respective \n",
    "    label.\n",
    "    \n",
    "    Parameters:\n",
    "        X (Pandas DataFrame): a dataframe that contains collisions\n",
    "        \n",
    "    Returns:\n",
    "        X, Y (Pandas DataFrames): tuple of DataFrames that have features and labels of \n",
    "                                  collisions, respectively\n",
    "    \"\"\"\n",
    "    X = collision\n",
    "    Y = collision['SEVERITY SCORE']\n",
    "    \n",
    "    # Convert BOROUGH to one-hot encoding\n",
    "    if 'BOROUGH' in X.columns:\n",
    "        borough_onehot = pd.get_dummies(X['BOROUGH']).astype(int)\n",
    "        X = pd.concat([X, borough_onehot], axis=1)\n",
    "    \n",
    "    # Drop unneeded columns\n",
    "    columns_to_drop = ['BOROUGH', 'ZIP CODE', 'LATITUDE', 'LONGITUDE', \n",
    "                       'ON STREET NAME', 'CROSS STREET NAME', 'SEVERITY SCORE', \n",
    "                       'UNIQUE KEY']\n",
    "    for column in columns_to_drop:\n",
    "        if column in X.columns:\n",
    "            X = X.drop(column, axis=1)\n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "# The number of collisions we have\n",
    "num_collisions_total = collision.shape[0]\n",
    "# Number of collisions we want in our training set\n",
    "num_collisions_training = 40000\n",
    "# Number of collisions we want in our test/validation set\n",
    "num_collisions_test = 4000\n",
    "\n",
    "# Get a random choice of collisions\n",
    "collisions_shuffled = collision.loc[np.random.choice(num_collisions_total, (num_collisions_training + num_collisions_test), replace=False), :]\n",
    "training_collisions = collisions_shuffled[:num_collisions_training]\n",
    "test_collisions = collisions_shuffled[num_collisions_training:]\n",
    "X_tr, Y_tr = get_training_sets(training_collisions)\n",
    "X_te, Y_te = get_training_sets(test_collisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Throw out all the features but the time of day\n",
    "time_of_day_features = ['NIGHT_TIME', 'MORNING_RUSH', 'DAY_TIME', 'EVENING_RUSH']\n",
    "X_tr_time = X_tr.loc[:, time_of_day_features]\n",
    "X_te_time = X_te.loc[:, time_of_day_features]\n",
    "\n",
    "# Train the classifier on the 'time of day' features\n",
    "classifier = linear_model.LogisticRegressionCV()\n",
    "classifier.fit_transform(X_tr_time, Y_tr)\n",
    "score = classifier.score(X_te_time, Y_te)\n",
    "\n",
    "# Assess the score of the classifier through the validation set\n",
    "accuracy = '{:.4f}%'.format(score * 100)\n",
    "print 'Just time of day:', accuracy, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As you can observe, the time of day wasn't much better at predicting the severity of collisions than the baseline. \n",
    "\n",
    "Let's try another feature: the borough. We will see if the general area is a good indicator of the severity of collisions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Throw out all the features but the borough\n",
    "borough_features = ['BRONX', 'BROOKLYN', 'MANHATTAN', 'QUEENS', 'STATEN ISLAND']\n",
    "X_tr_borough = X_tr.loc[:, borough_features]\n",
    "X_te_borough = X_te.loc[:, borough_features]\n",
    "\n",
    "# Train the classifier on the 'borough' features\n",
    "classifier = linear_model.LogisticRegressionCV()\n",
    "classifier.fit_transform(X_tr_borough, Y_tr)\n",
    "score = classifier.score(X_te_borough, Y_te)\n",
    "\n",
    "# Assess the score of the classifier through the validation set\n",
    "accuracy = '{:.4f}%'.format(score * 100)\n",
    "print 'Just borough:', accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As you can observe, the borough wasn't much better at predicting the severity of collisions than the baseline either. It's as bad as just using the time of day. \n",
    "\n",
    "Now, let's use all of our features and see how good they are at predicting the severity of collisions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train the classifier on all the features\n",
    "classifier = linear_model.LogisticRegressionCV()\n",
    "classifier.fit_transform(X_tr, Y_tr)\n",
    "score = classifier.score(X_te, Y_te)\n",
    "\n",
    "# Assess the score of the classifier through the validation set\n",
    "accuracy = '{:.4f}%'.format(score * 100)\n",
    "print 'All the features:', accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah, now we're talking! We can very good predictions (95% - 96% accuracy) by using all the features. It seems like the features we chose, combined, create a good predictor of the severity of collisions.\n",
    "\n",
    "This could give first-response units proactive information on the severity of the collisions and allow them to respond with the appropriate amount of resources. For example, when the emergency services get notified of a collision, they can use the location & time information and the types of vehicles involved in the collison to predict the severity before they even arrive to the scene. They can then route 2 ambulances (instead of just 1) to the area before they even see the severity themselves, potentially saving lives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "collision1 = collision.drop(['ON STREET NAME', 'CROSS STREET NAME', 'UNIQUE KEY'], axis=1)\n",
    "plotFeature(collision1, 'MANHATTAN', ['NIGHT_TIME', 'MOTORCYCLE'], 'file', 'page', 4000, severity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "collectn_1 = np.random.normal(100, 10, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def whiskerChart(X, min_percentile, max_percentile):\n",
    "    #X = X[X['SEVERITY SCORE'] < np.percentile(X['SEVERITY SCORE'],max_percentile)]\n",
    "    #X = X[X['SEVERITY SCORE'] > np.percentile(X['SEVERITY SCORE'],min_percentile)]\n",
    "    \n",
    "    data = []\n",
    "    labels = []\n",
    "    vehicles = ['BICYCLE', 'BUS', 'PASSENGER VEHICLE', 'TAXI', 'VAN', 'MOTORCYCLE', 'LARGE COM VEH(6 OR MORE TIRES)',\n",
    "               'PICK-UP TRUCK', 'SMALL COM VEH(4 TIRES)', 'SPORT UTILITY / STATION WAGON']\n",
    "    \n",
    "    i = 0\n",
    "    for vehicle in vehicles:\n",
    "        assignment = X.loc[X[vehicle] == 1, :]\n",
    "        data.append(assignment['SEVERITY SCORE'].values)\n",
    "        labels.append(\"v\" + str(i))\n",
    "        i += 1\n",
    " \n",
    "    sns.set_style(\"whitegrid\")\n",
    "    ax = sns.boxplot(data=data, width=1)    \n",
    "    ax.set(ylabel='Vehicle Type', xlabel='Severity of Crash')\n",
    "    ax.set_xticklabels(vehicles)\n",
    "    \n",
    "    for item in ax.get_xticklabels():\n",
    "        item.set_rotation(70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "whiskerChart(collision1[collision1['BOROUGH']=='MANHATTAN'], 0, 100,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
