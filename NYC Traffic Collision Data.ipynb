{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Analyzing NYC Traffic Collision Data</center>\n",
    "## <center>A 15-688 Project by:</center><center><br/> Ahmet Emre Unal (ahmetemu)<br/><br/>Marco Peyrot (mpeyrotc)</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import matplotlib\n",
    "matplotlib.use('svg')\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import collections\n",
    "from scipy.cluster.vq import kmeans,vq\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "raw_data_file_name = 'NYPD_Motor_Vehicle_Collisions.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def load_data(file_name):\n",
    "    collision = pd.read_csv(file_name, \n",
    "                            na_filter=False, \n",
    "                            parse_dates={'DATE_COMBINED' : ['DATE', 'TIME']}, \n",
    "                            infer_datetime_format=True)\n",
    "    \n",
    "    # Remove rows that don't have the necessary data\n",
    "    columns_to_check_for_empty = ['LOCATION', 'LATITUDE', 'LONGITUDE', 'BOROUGH',\n",
    "                                  'ZIP CODE', 'ON STREET NAME', 'CROSS STREET NAME', \n",
    "                                  'VEHICLE TYPE CODE 1', 'VEHICLE TYPE CODE 1']\n",
    "    for column in columns_to_check_for_empty:\n",
    "        collision = collision[collision[column] != '']\n",
    "        collision = collision[collision[column] != 'UNKNOWN']\n",
    "\n",
    "    # Drop unneeded columns\n",
    "    columns_to_drop = ['CONTRIBUTING FACTOR VEHICLE 1', 'CONTRIBUTING FACTOR VEHICLE 2', \n",
    "                       'CONTRIBUTING FACTOR VEHICLE 3', 'CONTRIBUTING FACTOR VEHICLE 4', \n",
    "                       'CONTRIBUTING FACTOR VEHICLE 5', 'LOCATION', 'UNIQUE KEY',\n",
    "                       'OFF STREET NAME', 'VEHICLE TYPE CODE 2', 'VEHICLE TYPE CODE 3',\n",
    "                       'VEHICLE TYPE CODE 4', 'VEHICLE TYPE CODE 5']\n",
    "    for column in columns_to_drop:\n",
    "        collision = collision.drop(column, axis=1)\n",
    "        \n",
    "    # Set column types\n",
    "    collision['ZIP CODE'] = collision['ZIP CODE'].astype(int)\n",
    "    collision['LATITUDE'] = collision['LATITUDE'].astype(float)\n",
    "    collision['LONGITUDE'] = collision['LONGITUDE'].astype(float)\n",
    "    \n",
    "    # Rename date column to just 'DATE'\n",
    "    collision = collision.rename(columns={'DATE_COMBINED':'DATE'})\n",
    "    \n",
    "    # Eliminate duplicates\n",
    "    collision = collision.drop_duplicates()\n",
    "    \n",
    "    # Reset index\n",
    "    collision = collision.reset_index(drop=True)\n",
    "    \n",
    "    return collision\n",
    "\n",
    "def create_temporal_features(collision):\n",
    "    collision = _create_time_features(collision)\n",
    "    collision = _create_date_features(collision)\n",
    "    \n",
    "    # We're done with date, we can drop it\n",
    "    collision = collision.drop('DATE', axis=1)\n",
    "    \n",
    "    return collision\n",
    "    \n",
    "\n",
    "def _create_time_features(collision):\n",
    "    # Create one-hot time of day representation\n",
    "    ## Date part is unimportant\n",
    "    morning_rush_begin = pd.datetime(2000, 01, 01, 07, 00, 00).time()\n",
    "    morning_rush_end = pd.datetime(2000, 01, 01, 11, 00, 00).time()\n",
    "    evening_rush_begin = pd.datetime(2000, 01, 01, 16, 00, 00).time()\n",
    "    evening_rush_end = pd.datetime(2000, 01, 01, 20, 00, 00).time()\n",
    "    collision_time = collision['DATE'].dt.time\n",
    "    \n",
    "    ## Night Time 00:00-06:59 & 20:00-00:00\n",
    "    night_time = (collision_time >= evening_rush_end) | (collision_time < morning_rush_begin)\n",
    "    night_time_onehot = pd.get_dummies(night_time).loc[:, True].astype(int)\n",
    "    collision = collision.assign(NIGHT_TIME = night_time_onehot.values)\n",
    "    \n",
    "    ## Morning Rush 07:00-10:59\n",
    "    morning_rush = (collision_time >= morning_rush_begin) & (collision_time < morning_rush_end)\n",
    "    morning_rush_onehot = pd.get_dummies(morning_rush).loc[:, True].astype(int)\n",
    "    collision = collision.assign(MORNING_RUSH = morning_rush_onehot.values)\n",
    "    \n",
    "    ## Night time 00:00-06:59 & 20:00-00:00\n",
    "    day_time = (collision_time >= morning_rush_end) & (collision_time < evening_rush_begin)\n",
    "    day_time_onehot = pd.get_dummies(day_time).loc[:, True].astype(int)\n",
    "    collision = collision.assign(DAY_TIME = day_time_onehot.values)\n",
    "    \n",
    "    ## Evening Rush 16:00-19:59\n",
    "    evening_rush = (collision_time >= evening_rush_begin) & (collision_time < evening_rush_end)\n",
    "    evening_rush_onehot = pd.get_dummies(evening_rush).loc[:, True].astype(int)\n",
    "    collision = collision.assign(EVENING_RUSH = evening_rush_onehot.values)\n",
    "    \n",
    "    return collision\n",
    "\n",
    "def _create_date_features(collision):\n",
    "    # Create one-hot weekday/weekend representation\n",
    "    collision_day = collision['DATE'].dt.dayofweek\n",
    "    \n",
    "    ## Weekday 0, 1, 2, 3, 4\n",
    "    ## Weekend 5, 6\n",
    "    is_weekday = (collision_day <= 4)\n",
    "    is_weekday_onehot = pd.get_dummies(is_weekday).astype(int)\n",
    "    \n",
    "    ## Weekday\n",
    "    weekday_onehot = is_weekday_onehot.loc[:, True]\n",
    "    collision = collision.assign(WEEKDAY = weekday_onehot.values)\n",
    "\n",
    "    ## Weekend\n",
    "    weekend_onehot = is_weekday_onehot.loc[:, False]\n",
    "    collision = collision.assign(WEEKEND = weekend_onehot.values)\n",
    "    \n",
    "    return collision\n",
    "\n",
    "def create_vehicle_features(collision):\n",
    "    # Create one-hot vehicle type representation\n",
    "    vehicle_types_onehot = pd.get_dummies(collision.loc[:, 'VEHICLE TYPE CODE 1']).astype(int)\n",
    "    \n",
    "    # Merge Motorcycle & Scooter columns\n",
    "    motorcycle = vehicle_types_onehot.loc[:, 'MOTORCYCLE'] + vehicle_types_onehot.loc[:, 'SCOOTER']\n",
    "    vehicle_types_onehot = vehicle_types_onehot.drop('MOTORCYCLE', axis=1)\n",
    "    vehicle_types_onehot = vehicle_types_onehot.drop('SCOOTER', axis=1)\n",
    "    vehicle_types_onehot = vehicle_types_onehot.assign(MOTORCYCLE = motorcycle.values)\n",
    "    \n",
    "    # Concatanate one-hot with collisions\n",
    "    collision = pd.concat([collision, vehicle_types_onehot], axis=1)\n",
    "    \n",
    "    # Drop unneeded collisions\n",
    "    vehicles_to_drop = ['OTHER', 'AMBULANCE', 'PEDICAB', 'FIRE TRUCK', 'LIVERY VEHICLE']\n",
    "    collisions_to_drop = vehicle_types_onehot.loc[:, vehicles_to_drop[0]]\n",
    "    for i in xrange(1, len(vehicles_to_drop)):  # Start from 1 since we already have OTHER\n",
    "        collisions_to_drop += vehicle_types_onehot.loc[:, vehicles_to_drop[i]]\n",
    "    collisions_to_keep = (collisions_to_drop == 0)\n",
    "    collision = collision[collisions_to_keep]\n",
    "    collision = collision.reset_index(drop=True)  # Reset index due to dropped rows\n",
    "    \n",
    "    # Drop unneeded vehicle columns\n",
    "    for column in vehicles_to_drop:\n",
    "        collision = collision.drop(column, axis=1)\n",
    "    \n",
    "    # Drop vehicle type column\n",
    "    collision = collision.drop('VEHICLE TYPE CODE 1', axis=1)\n",
    "        \n",
    "    return collision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load the collision data\n",
    "collision = load_data(raw_data_file_name)\n",
    "collision = create_temporal_features(collision)\n",
    "collision = create_vehicle_features(collision)\n",
    "    \n",
    "print collision.head(6)\n",
    "print collision.dtypes\n",
    "print len(collision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def parse_page(html):\n",
    "    \"\"\"\n",
    "    Parse the table contained in the bycicle lanes webpage.\n",
    "\n",
    "    Args:\n",
    "        html (string): String of HTML corresponding to the data source webpage.\n",
    "\n",
    "    Returns:\n",
    "        a dictionary that contains mappings from a category to the list containing the data.\n",
    "        These categories are: street, begins, ends, and borough.\n",
    "    \"\"\"\n",
    "\n",
    "    # Write solution here\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    result = {\n",
    "        'street': [],\n",
    "        'begins': [],\n",
    "        'ends': [],\n",
    "        'borough': []\n",
    "    }\n",
    "\n",
    "    table = soup.findChildren('tbody')[0]\n",
    "    rows = table.findChildren(['tr'])\n",
    "    \n",
    "    for row in rows:\n",
    "        cells = row.findChildren('td')\n",
    "        content = cells[0].text\n",
    "        m = re.search(r'^([a-zA-Z\\s0-9\\-\\.,\\(\\)]+) (from)*(between)* '\n",
    "                      r'([a-zA-Z\\s0-9\\-\\.,\\(\\)]+) (to)*(and)* '\n",
    "                      r'([a-zA-Z\\s0-9\\-\\.,\\(\\)]+)$', content)\n",
    "        \n",
    "        # content that does not follow this syntax is discarded because\n",
    "        # it refers to landscapes or parks.\n",
    "        if m is not None:\n",
    "            result['street'].append(m.group(1).upper())\n",
    "            result['begins'].append(m.group(4).upper())\n",
    "            result['ends'].append(m.group(7).upper())\n",
    "            result['borough'].append(cells[2].text.upper())\n",
    "            \n",
    "    df = pd.DataFrame(result)\n",
    "    \n",
    "    df.loc[df.borough == 'THE BRONX', 'borough'] = 'BRONX'\n",
    "    \n",
    "    df.rename(columns={'borough': 'BOROUGH', 'begins': 'BEGINS', 'ends': 'ENDS', 'street': 'ON STREET NAME'}, inplace=True)\n",
    "        \n",
    "    return df\n",
    "    \n",
    "def extract_bycicle_lanes(url):\n",
    "    \"\"\"\n",
    "    Retrieve all of the bycicle lane information for the city of New York.\n",
    "\n",
    "    Parameters:\n",
    "        url (string): page URL corresponding to the listing of bycicle lane information.\n",
    "\n",
    "    Returns:\n",
    "        bycicle_lanes (Pandas DataFrame): list of dictionaries containing extracted lane information.\n",
    "    \"\"\"\n",
    "    response = requests.get(url).text\n",
    "    result = parse_page(response)\n",
    "    \n",
    "    return result\n",
    "\n",
    "bycicle_lanes = extract_bycicle_lanes('http://www.nyc.gov/html/dot/html/bicyclists/lane-list.shtml')\n",
    "print collision.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def merge_bycicle_lanes(df1, df2, columns):\n",
    "    \"\"\"\n",
    "    merge the both dataframes on the specified columns.\n",
    "\n",
    "    Parameters:\n",
    "        df1 (DataFrame): pandas dataframe containing some data.\n",
    "        df2 (DataFrame): pandas dataframe containing some data.\n",
    "\n",
    "    Returns:\n",
    "        result (Pandas DataFrame): dataframe containing data from both dataframes.\n",
    "    \"\"\"\n",
    "    result = pd.merge(df1, df2, how='left', on=columns)\n",
    "    result = result.assign(HAS_LANE = [0 if x is np.nan else 1 for x in result.loc[:, 'BEGINS']])\n",
    "    \n",
    "    result = result.drop('BEGINS', 1)\n",
    "    result = result.drop('ENDS', 1)\n",
    "    \n",
    "    return result.drop_duplicates()\n",
    "\n",
    "print collision.columns\n",
    "collision = merge_bycicle_lanes(collision, bycicle_lanes, ['ON STREET NAME', 'BOROUGH'])\n",
    "print collision.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "collision1 = collision.drop(['BOROUGH', 'ON STREET NAME', 'CROSS STREET NAME'], 1)\n",
    "collision1 = collision1.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def k_means_test(X, K_max):\n",
    "    \"\"\"\n",
    "    finds the best number k for the k_means algorithm according to some features passed to this\n",
    "    method.\n",
    "\n",
    "    Parameters:\n",
    "        X (DataFrame): pandas dataframe containing the features that will be used to divide the\n",
    "        data into clusters.\n",
    "        K-max (Integer): the maximum number of K clusters to test on.\n",
    "\n",
    "    Returns:\n",
    "        Nothing, it just plots the elbow graph that has a marker on the best number of\n",
    "        clusters to use.\n",
    "    \"\"\"\n",
    "    K = range(1,K_max)\n",
    "    KM = [kmeans(X,k) for k in K]\n",
    "    centroids = [cent for (cent,var) in KM]\n",
    "\n",
    "    D_k = [cdist(X, cent, 'euclidean') for cent in centroids]\n",
    "    cIdx = [np.argmin(D,axis=1) for D in D_k]\n",
    "    dist = [np.min(D,axis=1) for D in D_k]\n",
    "    avgWithinSS = [sum(d)/X.shape[0] for d in dist]\n",
    "\n",
    "    kIdx = min([(v,i) for i,v in enumerate([((x*100) + y)/2.0 for x,y in zip(avgWithinSS, K)])])[1]\n",
    "\n",
    "    # plot elbow curve\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(K, avgWithinSS, 'b*-')\n",
    "    ax.plot(K[kIdx], avgWithinSS[kIdx], marker='o', markersize=12, \n",
    "            markeredgewidth=2, markeredgecolor='r', markerfacecolor='None')\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('Average within-cluster sum of squares')\n",
    "    plt.title('Elbow for KMeans clustering')\n",
    "\n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate different centroids according to different number of k's.\n",
    "k_means_test(collision1.loc[:,['LATITUDE', 'LONGITUDE']], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
